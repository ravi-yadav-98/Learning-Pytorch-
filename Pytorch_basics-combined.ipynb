{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWLC5HMAyY3-"
   },
   "source": [
    "# Deep Learning with PyTorch Step-by-Step: A Beginner's Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-MvpSz-ryY4A"
   },
   "source": [
    "# Chapter 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QSzv-NRNyY4A"
   },
   "outputs": [],
   "source": [
    "from config_dl import *\n",
    "from plots.chapter1 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BMhQQgK4yY4B"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrKLFkgAyY4B"
   },
   "source": [
    "# A Simple Regression Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFQgdk8AyY4B"
   },
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnkhIBsayY4C"
   },
   "source": [
    "### Synthetic Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RhxnuT3AyY4C"
   },
   "outputs": [],
   "source": [
    "true_b = 1\n",
    "true_w = 2\n",
    "N = 100\n",
    "\n",
    "# Data Generation\n",
    "np.random.seed(42)\n",
    "x = np.random.rand(N, 1)\n",
    "epsilon = (.1 * np.random.randn(N, 1))\n",
    "y = true_b + true_w * x + epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-zI7Dy5yY4C"
   },
   "source": [
    "### Cell 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DM0J4fITyY4C"
   },
   "outputs": [],
   "source": [
    "# Shuffles the indices\n",
    "idx = np.arange(N)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "# Uses first 80 random indices for train\n",
    "train_idx = idx[:int(N*.8)]\n",
    "# Uses the remaining indices for validation\n",
    "val_idx = idx[int(N*.8):]\n",
    "\n",
    "# Generates train and validation sets\n",
    "x_train, y_train = x[train_idx], y[train_idx]\n",
    "x_val, y_val = x[val_idx], y[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3hWr3492yY4D"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'figure1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mfigure1\u001b[49m(x_train, y_train, x_val, y_val)\n",
      "\u001b[31mNameError\u001b[39m: name 'figure1' is not defined"
     ]
    }
   ],
   "source": [
    "figure1(x_train, y_train, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aC_mabQayY4E"
   },
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eNyqlUZsyY4E"
   },
   "source": [
    "## Step 0: Random Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "D3YhObHxyY4E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49671415] [-0.1382643]\n"
     ]
    }
   ],
   "source": [
    "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
    "np.random.seed(42)\n",
    "b = np.random.randn(1)\n",
    "w = np.random.randn(1)\n",
    "\n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LcjE0Lx8yY4E"
   },
   "source": [
    "## Step 1: Compute Model's Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "clocWjkhyY4E"
   },
   "outputs": [],
   "source": [
    "# Step 1 - Computes our model's predicted output - forward pass\n",
    "yhat = b + w * x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDZaGmpayY4F"
   },
   "source": [
    "## Step 2: Compute the Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "heyDehdNyY4F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7421577700550976\n"
     ]
    }
   ],
   "source": [
    "# Step 2 - Computing the loss\n",
    "# We are using ALL data points, so this is BATCH gradient\n",
    "# descent. How wrong is our model? That's the error!\n",
    "error = (yhat - y_train)\n",
    "\n",
    "# It is a regression, so it computes mean squared error (MSE)\n",
    "loss = (error ** 2).mean()\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UXnwOTEyY4F"
   },
   "source": [
    "## Step 3: Compute the Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "UfXGiGWxyY4F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.044811379650508 -1.8337537171510832\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
    "b_grad = 2 * error.mean()\n",
    "w_grad = 2 * (x_train * error).mean()\n",
    "print(b_grad, w_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZGSJEWdyY4G"
   },
   "source": [
    "## Step 4: Update the Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Ghx1yYanyY4G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49671415] [-0.1382643]\n",
      "[0.80119529] [0.04511107]\n"
     ]
    }
   ],
   "source": [
    "# Sets learning rate - this is \"eta\" ~ the \"n\" like Greek letter\n",
    "lr = 0.1\n",
    "print(b, w)\n",
    "\n",
    "# Step 4 - Updates parameters using gradients and \n",
    "# the learning rate\n",
    "b = b - lr * b_grad\n",
    "w = w - lr * w_grad\n",
    "\n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IkEEjMlmyY4G"
   },
   "source": [
    "## Step 5: Rinse and Repeat!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKqZGl4gyY4G"
   },
   "outputs": [],
   "source": [
    "# Go back to Step 1 and run observe how your parameters b and w change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4ygK45VyY4G"
   },
   "source": [
    "# Linear Regression in Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10Cyal-6yY4H"
   },
   "source": [
    "### Cell 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "365RJJViyY4H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49671415] [-0.1382643]\n",
      "[1.02354094] [1.96896411]\n"
     ]
    }
   ],
   "source": [
    "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
    "np.random.seed(42)\n",
    "b = np.random.randn(1)\n",
    "w = np.random.randn(1)\n",
    "\n",
    "print(b, w)\n",
    "\n",
    "# Sets learning rate - this is \"eta\" ~ the \"n\"-like Greek letter\n",
    "lr = 0.1\n",
    "# Defines number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Step 1 - Computes model's predicted output - forward pass\n",
    "    yhat = b + w * x_train\n",
    "    \n",
    "    # Step 2 - Computes the loss\n",
    "    # We are using ALL data points, so this is BATCH gradient\n",
    "    # descent. How wrong is our model? That's the error!   \n",
    "    error = (yhat - y_train)\n",
    "    # It is a regression, so it computes mean squared error (MSE)\n",
    "    loss = (error ** 2).mean()\n",
    "    \n",
    "    # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
    "    b_grad = 2 * error.mean()\n",
    "    w_grad = 2 * (x_train * error).mean()\n",
    "    \n",
    "    # Step 4 - Updates parameters using gradients and \n",
    "    # the learning rate\n",
    "    b = b - lr * b_grad\n",
    "    w = w - lr * w_grad\n",
    "    \n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "GHmhYiLIyY4H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.02354075] [1.96896447]\n"
     ]
    }
   ],
   "source": [
    "# Sanity Check: do we get the same results as our\n",
    "# gradient descent?\n",
    "linr = LinearRegression()\n",
    "linr.fit(x_train, y_train)\n",
    "print(linr.intercept_, linr.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "1lOAw0dYyY4H"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'figure3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m fig = \u001b[43mfigure3\u001b[49m(x_train, y_train)\n",
      "\u001b[31mNameError\u001b[39m: name 'figure3' is not defined"
     ]
    }
   ],
   "source": [
    "fig = figure3(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StXDn4jFyY4I"
   },
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fh-7KTtGyY4I"
   },
   "source": [
    "## Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "alLRb_O6yY4I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1416)\n",
      "tensor([1, 2, 3])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[[ 1.0539,  0.7020, -0.3619, -0.6641],\n",
      "         [ 0.7322, -1.3365, -0.3675, -0.4683],\n",
      "         [ 0.1711,  1.5631,  1.1042, -1.1722]],\n",
      "\n",
      "        [[-0.2490, -0.5424,  0.9580, -0.2838],\n",
      "         [-0.4907,  0.4868, -0.7799, -0.1772],\n",
      "         [-0.3324, -0.7467, -0.3820, -0.7606]]])\n"
     ]
    }
   ],
   "source": [
    "scalar = torch.tensor(3.14159)\n",
    "vector = torch.tensor([1, 2, 3])\n",
    "matrix = torch.ones((2, 3), dtype=torch.float)\n",
    "tensor = torch.randn((2, 3, 4), dtype=torch.float)\n",
    "\n",
    "print(scalar)\n",
    "print(vector)\n",
    "print(matrix)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "uFqtaS3YyY4I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4]) torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(tensor.size(), tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "8KJukqpKyY4I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "print(scalar.size(), scalar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Lry1VlolyY4J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 2., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# We get a tensor with a different shape but it still is\n",
    "# the SAME tensor\n",
    "same_matrix = matrix.view(1, 6)\n",
    "# If we change one of its elements...\n",
    "same_matrix[0, 1] = 2.\n",
    "# It changes both variables: matrix and same_matrix\n",
    "print(matrix)\n",
    "print(same_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "1yhoy-iRyY4J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 3., 1., 1., 1., 1.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ravi.Yadav\\AppData\\Local\\Temp\\ipykernel_4568\\1277334554.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  different_matrix = matrix.new_tensor(matrix.view(1, 6))\n"
     ]
    }
   ],
   "source": [
    "# We can use \"new_tensor\" method to REALLY copy it into a new one\n",
    "different_matrix = matrix.new_tensor(matrix.view(1, 6))\n",
    "# Now, if we change one of its elements...\n",
    "different_matrix[0, 1] = 3.\n",
    "# The original tensor (matrix) is left untouched!\n",
    "# But we get a \"warning\" from PyTorch telling us \n",
    "# to use \"clone()\" instead!\n",
    "print(matrix)\n",
    "print(different_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "fwxsTU87yY4J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 4., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Lets follow PyTorch's suggestion and use \"clone\" method\n",
    "another_matrix = matrix.view(1, 6).clone().detach()\n",
    "# Again, if we change one of its elements...\n",
    "another_matrix[0, 1] = 4.\n",
    "# The original tensor (matrix) is left untouched!\n",
    "print(matrix)\n",
    "print(another_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "he0RKFoMyY4J"
   },
   "source": [
    "## Loading Data, Devices and CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "95rOY2BlyY4K"
   },
   "outputs": [],
   "source": [
    "x_train_tensor = torch.as_tensor(x_train)\n",
    "x_train.dtype, x_train_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "thfUQU8GyY4K"
   },
   "outputs": [],
   "source": [
    "float_tensor = x_train_tensor.float()\n",
    "float_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "oVvAjERSyY4K"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_array = np.array([1, 2, 3])\n",
    "dummy_tensor = torch.as_tensor(dummy_array)\n",
    "# Modifies the numpy array\n",
    "dummy_array[1] = 0\n",
    "# Tensor gets modified too...\n",
    "dummy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "lmW5F0ItyY4K"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_tensor.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lS48mUwxyY4L"
   },
   "source": [
    "### Defining your device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "2Xn1kGfvyY4L"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ac4BVRW9yY4L"
   },
   "outputs": [],
   "source": [
    "n_cudas = torch.cuda.device_count()\n",
    "for i in range(n_cudas):\n",
    "    print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "4rYba4H-yY4L"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7713], dtype=torch.float64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_tensor = torch.as_tensor(x_train).to(device)\n",
    "gpu_tensor[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V25EuOIdyY4L"
   },
   "source": [
    "### Cell 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "UWCFf9IQyY4L",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Our data was in Numpy arrays, but we need to transform them \n",
    "# into PyTorch's Tensors and then we send them to the \n",
    "# chosen device\n",
    "x_train_tensor = torch.as_tensor(x_train).float().to(device)\n",
    "y_train_tensor = torch.as_tensor(y_train).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "SP_ndl8zyY4M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'torch.Tensor'> torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# Here we can see the difference - notice that .type() is more\n",
    "# useful since it also tells us WHERE the tensor is (device)\n",
    "print(type(x_train), type(x_train_tensor), x_train_tensor.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VTNRgSREyY4M"
   },
   "outputs": [],
   "source": [
    "# Uncomment and Run this cell\n",
    "# This gives an error since when converting GPU tensor back to a Numpy array, Numpy cannot handle GPU tensors.\n",
    "\n",
    "# back_to_numpy = x_train_tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "-7Eivmf_yY4M"
   },
   "outputs": [],
   "source": [
    "# Therefore, you first need to make them CPU tensors using cpu()\n",
    "back_to_numpy = x_train_tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6uSAqV2yY4M"
   },
   "source": [
    "## Creating Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "t3VTnlCwyY4M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# FIRST\n",
    "# Initializes parameters \"b\" and \"w\" randomly, ALMOST as we\n",
    "# did in Numpy since we want to apply gradient descent on\n",
    "# these parameters we need to set REQUIRES_GRAD = TRUE\n",
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
    "w = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "kzHINNQYyY4N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# SECOND\n",
    "# But what if we want to run it on a GPU? We could just\n",
    "# send them to device, right?\n",
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float).to(device)\n",
    "w = torch.randn(1, requires_grad=True, dtype=torch.float).to(device)\n",
    "print(b, w)\n",
    "# Sorry, but NO! The to(device) \"shadows\" the gradient..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "uESo292ByY4N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# THIRD\n",
    "# We can either create regular tensors and send them to\n",
    "# the device (as we did with our data)\n",
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, dtype=torch.float).to(device)\n",
    "w = torch.randn(1, dtype=torch.float).to(device)\n",
    "# and THEN set them as requiring gradients...\n",
    "b.requires_grad_()\n",
    "w.requires_grad_()\n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyuOimWjyY4N"
   },
   "source": [
    "### Cell 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "hg6AMCqEyY4N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# FINAL\n",
    "# We can specify the device at the moment of creation\n",
    "# RECOMMENDED!\n",
    "\n",
    "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, requires_grad=True, \\\n",
    "                dtype=torch.float, device=device)\n",
    "w = torch.randn(1, requires_grad=True, \\\n",
    "                dtype=torch.float, device=device)\n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2qN9fwiyY4O"
   },
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fo5CBuZxyY4O"
   },
   "source": [
    "## backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8CVsB1FyY4O"
   },
   "source": [
    "### Cell 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "PeJ7mvtTyY4O"
   },
   "outputs": [],
   "source": [
    "# Step 1 - Computes our model's predicted output - forward pass\n",
    "yhat = b + w * x_train_tensor\n",
    "\n",
    "# Step 2 - Computes the loss\n",
    "# We are using ALL data points, so this is BATCH gradient descent\n",
    "# How wrong is our model? That's the error! \n",
    "error = (yhat - y_train_tensor)\n",
    "# It is a regression, so it computes mean squared error (MSE)\n",
    "loss = (error ** 2).mean()\n",
    "\n",
    "# Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
    "# No more manual computation of gradients! \n",
    "# b_grad = 2 * error.mean()\n",
    "# w_grad = 2 * (x_tensor * error).mean()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ghcEy5FQyY4P"
   },
   "outputs": [],
   "source": [
    "print(error.requires_grad, yhat.requires_grad, \\\n",
    "      b.requires_grad, w.requires_grad)\n",
    "print(y_train_tensor.requires_grad, x_train_tensor.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JeqPXn8AyY4P"
   },
   "source": [
    "## grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "DwvojcgXyY4P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.1125]) tensor([-1.8156])\n"
     ]
    }
   ],
   "source": [
    "print(b.grad, w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qIes52csyY4P"
   },
   "outputs": [],
   "source": [
    "# Just run the two cells above one more time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ctXPBqMkyY4Q"
   },
   "source": [
    "## zero_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "_RW_9e99yY4Q"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.]), tensor([0.]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code will be placed *after* Step 4\n",
    "# (updating the parameters)\n",
    "b.grad.zero_(), w.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Df8eVjFqyY4Q"
   },
   "source": [
    "## Updating Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCwV0t8RyY4Q"
   },
   "source": [
    "### Cell 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "WXtVifQSyY4Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Sets learning rate - this is \"eta\" ~ the \"n\"-like Greek letter\n",
    "lr = 0.1\n",
    "\n",
    "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, requires_grad=True, \\\n",
    "                dtype=torch.float, device=device)\n",
    "w = torch.randn(1, requires_grad=True, \\\n",
    "                dtype=torch.float, device=device)\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Step 1 - Computes model's predicted output - forward pass\n",
    "    yhat = b + w * x_train_tensor\n",
    "    \n",
    "    # Step 2 - Computes the loss\n",
    "    # We are using ALL data points, so this is BATCH gradient\n",
    "    # descent. How wrong is our model? That's the error!\n",
    "    error = (yhat - y_train_tensor)\n",
    "    # It is a regression, so it computes mean squared error (MSE)\n",
    "    loss = (error ** 2).mean()\n",
    "\n",
    "    # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
    "    # No more manual computation of gradients! \n",
    "    # b_grad = 2 * error.mean()\n",
    "    # w_grad = 2 * (x_tensor * error).mean()   \n",
    "    # We just tell PyTorch to work its way BACKWARDS \n",
    "    # from the specified loss!\n",
    "    loss.backward()\n",
    "    \n",
    "    # Step 4 - Updates parameters using gradients and \n",
    "    # the learning rate. But not so fast...\n",
    "    # FIRST ATTEMPT - just using the same code as before\n",
    "    # AttributeError: 'NoneType' object has no attribute 'zero_'\n",
    "    # b = b - lr * b.grad\n",
    "    # w = w - lr * w.grad\n",
    "    # print(b)\n",
    "\n",
    "    # SECOND ATTEMPT - using in-place Python assigment\n",
    "    # RuntimeError: a leaf Variable that requires grad\n",
    "    # has been used in an in-place operation.\n",
    "    # b -= lr * b.grad\n",
    "    # w -= lr * w.grad        \n",
    "    \n",
    "    # THIRD ATTEMPT - NO_GRAD for the win!\n",
    "    # We need to use NO_GRAD to keep the update out of\n",
    "    # the gradient computation. Why is that? It boils \n",
    "    # down to the DYNAMIC GRAPH that PyTorch uses...\n",
    "    with torch.no_grad():\n",
    "        b -= lr * b.grad\n",
    "        w -= lr * w.grad\n",
    "    \n",
    "    # PyTorch is \"clingy\" to its computed gradients, we\n",
    "    # need to tell it to let it go...\n",
    "    b.grad.zero_()\n",
    "    w.grad.zero_()\n",
    "    \n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8WUoAflyY4R"
   },
   "source": [
    "## no_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MBpFsvGAyY4R"
   },
   "outputs": [],
   "source": [
    "# This is what we used in the THIRD ATTEMPT..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMREmb0XyY4R"
   },
   "source": [
    "# Dynamic Computation Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "88Oz4ePdyY4R"
   },
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Projects\\Learning-Pytorch-\\.venv\\Lib\\site-packages\\graphviz\\backend\\execute.py:76\u001b[39m, in \u001b[36mrun_check\u001b[39m\u001b[34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[39m\n\u001b[32m     75\u001b[39m         kwargs[\u001b[33m'\u001b[39m\u001b[33mstdout\u001b[39m\u001b[33m'\u001b[39m] = kwargs[\u001b[33m'\u001b[39m\u001b[33mstderr\u001b[39m\u001b[33m'\u001b[39m] = subprocess.PIPE\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     proc = \u001b[43m_run_input_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_lines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Projects\\Learning-Pytorch-\\.venv\\Lib\\site-packages\\graphviz\\backend\\execute.py:96\u001b[39m, in \u001b[36m_run_input_lines\u001b[39m\u001b[34m(cmd, input_lines, kwargs)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_input_lines\u001b[39m(cmd, input_lines, *, kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     popen = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdin\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m     stdin_write = popen.stdin.write\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py:1026\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1023\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1024\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1036\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py:1538\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[39m\n\u001b[32m   1537\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1538\u001b[39m     hp, ht, pid, tid = \u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1539\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[32m   1540\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1541\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1542\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1544\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1545\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1546\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1547\u001b[39m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[32m   1548\u001b[39m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1551\u001b[39m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[32m   1552\u001b[39m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 2] The system cannot find the file specified",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mExecutableNotFound\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Projects\\Learning-Pytorch-\\.venv\\Lib\\site-packages\\IPython\\core\\formatters.py:1036\u001b[39m, in \u001b[36mMimeBundleFormatter.__call__\u001b[39m\u001b[34m(self, obj, include, exclude)\u001b[39m\n\u001b[32m   1033\u001b[39m     method = get_real_method(obj, \u001b[38;5;28mself\u001b[39m.print_method)\n\u001b[32m   1035\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1036\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Projects\\Learning-Pytorch-\\.venv\\Lib\\site-packages\\graphviz\\jupyter_integration.py:98\u001b[39m, in \u001b[36mJupyterIntegration._repr_mimebundle_\u001b[39m\u001b[34m(self, include, exclude, **_)\u001b[39m\n\u001b[32m     96\u001b[39m include = \u001b[38;5;28mset\u001b[39m(include) \u001b[38;5;28;01mif\u001b[39;00m include \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;28mself\u001b[39m._jupyter_mimetype}\n\u001b[32m     97\u001b[39m include -= \u001b[38;5;28mset\u001b[39m(exclude \u001b[38;5;129;01mor\u001b[39;00m [])\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {mimetype: \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m mimetype, method_name \u001b[38;5;129;01min\u001b[39;00m MIME_TYPES.items()\n\u001b[32m    100\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m mimetype \u001b[38;5;129;01min\u001b[39;00m include}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Projects\\Learning-Pytorch-\\.venv\\Lib\\site-packages\\graphviz\\jupyter_integration.py:112\u001b[39m, in \u001b[36mJupyterIntegration._repr_image_svg_xml\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_repr_image_svg_xml\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    111\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the rendered graph as SVG string.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msvg\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSVG_ENCODING\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Projects\\Learning-Pytorch-\\.venv\\Lib\\site-packages\\graphviz\\piping.py:104\u001b[39m, in \u001b[36mPipe.pipe\u001b[39m\u001b[34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpipe\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[32m     56\u001b[39m          \u001b[38;5;28mformat\u001b[39m: typing.Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     57\u001b[39m          renderer: typing.Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     61\u001b[39m          engine: typing.Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     62\u001b[39m          encoding: typing.Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> typing.Union[\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the source piped through the Graphviz layout command.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    102\u001b[39m \u001b[33;03m        '<?xml version='\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pipe_legacy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mneato_no_op\u001b[49m\u001b[43m=\u001b[49m\u001b[43mneato_no_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Projects\\Learning-Pytorch-\\.venv\\Lib\\site-packages\\graphviz\\_tools.py:185\u001b[39m, in \u001b[36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    177\u001b[39m     wanted = \u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    178\u001b[39m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated.items())\n\u001b[32m    179\u001b[39m     warnings.warn(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m will be reduced\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    180\u001b[39m                   \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m positional arg\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mqualification\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    181\u001b[39m                   \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m as keyword arg\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m    182\u001b[39m                   stacklevel=stacklevel,\n\u001b[32m    183\u001b[39m                   category=category)\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Projects\\Learning-Pytorch-\\.venv\\Lib\\site-packages\\graphviz\\piping.py:121\u001b[39m, in \u001b[36mPipe._pipe_legacy\u001b[39m\u001b[34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;129m@_tools\u001b[39m.deprecate_positional_args(supported_number=\u001b[32m1\u001b[39m, ignore_arg=\u001b[33m'\u001b[39m\u001b[33mself\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_pipe_legacy\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[32m    114\u001b[39m                  \u001b[38;5;28mformat\u001b[39m: typing.Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    119\u001b[39m                  engine: typing.Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    120\u001b[39m                  encoding: typing.Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> typing.Union[\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pipe_future\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mneato_no_op\u001b[49m\u001b[43m=\u001b[49m\u001b[43mneato_no_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Projects\\Learning-Pytorch-\\.venv\\Lib\\site-packages\\graphviz\\piping.py:149\u001b[39m, in \u001b[36mPipe._pipe_future\u001b[39m\u001b[34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m codecs.lookup(encoding) \u001b[38;5;129;01mis\u001b[39;00m codecs.lookup(\u001b[38;5;28mself\u001b[39m.encoding):\n\u001b[32m    148\u001b[39m         \u001b[38;5;66;03m# common case: both stdin and stdout need the same encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pipe_lines_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    151\u001b[39m         raw = \u001b[38;5;28mself\u001b[39m._pipe_lines(*args, input_encoding=\u001b[38;5;28mself\u001b[39m.encoding, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Projects\\Learning-Pytorch-\\.venv\\Lib\\site-packages\\graphviz\\backend\\piping.py:212\u001b[39m, in \u001b[36mpipe_lines_string\u001b[39m\u001b[34m(engine, format, input_lines, encoding, renderer, formatter, neato_no_op, quiet)\u001b[39m\n\u001b[32m    206\u001b[39m cmd = dot_command.command(engine, \u001b[38;5;28mformat\u001b[39m,\n\u001b[32m    207\u001b[39m                           renderer=renderer,\n\u001b[32m    208\u001b[39m                           formatter=formatter,\n\u001b[32m    209\u001b[39m                           neato_no_op=neato_no_op)\n\u001b[32m    210\u001b[39m kwargs = {\u001b[33m'\u001b[39m\u001b[33minput_lines\u001b[39m\u001b[33m'\u001b[39m: input_lines, \u001b[33m'\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m'\u001b[39m: encoding}\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m proc = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m proc.stdout\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Projects\\Learning-Pytorch-\\.venv\\Lib\\site-packages\\graphviz\\backend\\execute.py:81\u001b[39m, in \u001b[36mrun_check\u001b[39m\u001b[34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e.errno == errno.ENOENT:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ExecutableNotFound(cmd) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet \u001b[38;5;129;01mand\u001b[39;00m proc.stderr:\n",
      "\u001b[31mExecutableNotFound\u001b[39m: failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x20c24407530>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, requires_grad=True, \\\n",
    "                dtype=torch.float, device=device)\n",
    "w = torch.randn(1, requires_grad=True, \\\n",
    "                dtype=torch.float, device=device)\n",
    "\n",
    "# Step 1 - Computes our model's predicted output - forward pass\n",
    "yhat = b + w * x_train_tensor\n",
    "\n",
    "# Step 2 - Computes the loss\n",
    "# We are using ALL data points, so this is BATCH gradient\n",
    "# descent. How wrong is our model? That's the error! \n",
    "error = (yhat - y_train_tensor)\n",
    "# It is a regression, so it computes mean squared error (MSE)\n",
    "loss = (error ** 2).mean()\n",
    "\n",
    "# We can try plotting the graph for any python variable: \n",
    "# yhat, error, loss...\n",
    "make_dot(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ek2hMsQAyY4R"
   },
   "outputs": [],
   "source": [
    "b_nograd = torch.randn(1, requires_grad=False, \\\n",
    "                       dtype=torch.float, device=device)\n",
    "w = torch.randn(1, requires_grad=True, \\\n",
    "                dtype=torch.float, device=device)\n",
    "\n",
    "yhat = b_nograd + w * x_train_tensor\n",
    "\n",
    "make_dot(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jt0jkiGFyY4S"
   },
   "outputs": [],
   "source": [
    "b = torch.randn(1, requires_grad=True, \\\n",
    "                dtype=torch.float, device=device)\n",
    "w = torch.randn(1, requires_grad=True, \\\n",
    "                dtype=torch.float, device=device)\n",
    "\n",
    "yhat = b + w * x_train_tensor\n",
    "error = yhat - y_train_tensor\n",
    "loss = (error ** 2).mean()\n",
    "\n",
    "# this makes no sense!!\n",
    "if loss > 0:\n",
    "    yhat2 = w * x_train_tensor\n",
    "    error2 = yhat2 - y_train_tensor\n",
    "    \n",
    "# neither does this :-)\n",
    "loss += error2.mean()\n",
    "\n",
    "make_dot(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MyL9005yY4S"
   },
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z29gacdZyY4S"
   },
   "source": [
    "## step / zero_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "-7RzYvbFyY4T"
   },
   "outputs": [],
   "source": [
    "# Defines a SGD optimizer to update the parameters\n",
    "optimizer = optim.SGD([b, w], lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmaf6B7OyY4T"
   },
   "source": [
    "### Cell 3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "txzP_NpKyY4T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Sets learning rate - this is \"eta\" ~ the \"n\"-like Greek letter\n",
    "lr = 0.1\n",
    "\n",
    "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, requires_grad=True, \\\n",
    "                dtype=torch.float, device=device)\n",
    "w = torch.randn(1, requires_grad=True, \\\n",
    "                dtype=torch.float, device=device)\n",
    "\n",
    "# Defines a SGD optimizer to update the parameters\n",
    "optimizer = optim.SGD([b, w], lr=lr)\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Step 1 - Computes model's predicted output - forward pass\n",
    "    yhat = b + w * x_train_tensor\n",
    "    \n",
    "    # Step 2 - Computes the loss\n",
    "    # We are using ALL data points, so this is BATCH gradient \n",
    "    # descent. How wrong is our model? That's the error! \n",
    "    error = (yhat - y_train_tensor)\n",
    "    # It is a regression, so it computes mean squared error (MSE)\n",
    "    loss = (error ** 2).mean()\n",
    "\n",
    "    # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    # Step 4 - Updates parameters using gradients and \n",
    "    # the learning rate. No more manual update!\n",
    "    # with torch.no_grad():\n",
    "    #     b -= lr * b.grad\n",
    "    #     w -= lr * w.grad\n",
    "    optimizer.step()\n",
    "    \n",
    "    # No more telling Pytorch to let gradients go!\n",
    "    # b.grad.zero_()\n",
    "    # w.grad.zero_()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rRzsZ9D4yY4T"
   },
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "JGlCuaH_yY4U"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSELoss()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defines a MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "gQnMAOyxyY4U"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1700)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a random example to illustrate the loss function\n",
    "predictions = torch.tensor([0.5, 1.0])\n",
    "labels = torch.tensor([2.0, 1.3])\n",
    "loss_fn(predictions, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vPBkM1GyY4U"
   },
   "source": [
    "### Cell 3.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "s6zRioBryY4U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Sets learning rate - this is \"eta\" ~ the \"n\"-like\n",
    "# Greek letter\n",
    "lr = 0.1\n",
    "\n",
    "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, requires_grad=True, \\\n",
    "                dtype=torch.float, device=device)\n",
    "w = torch.randn(1, requires_grad=True, \\\n",
    "                dtype=torch.float, device=device)\n",
    "\n",
    "# Defines a SGD optimizer to update the parameters\n",
    "optimizer = optim.SGD([b, w], lr=lr)\n",
    "\n",
    "# Defines a MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Step 1 - Computes model's predicted output - forward pass\n",
    "    yhat = b + w * x_train_tensor\n",
    "    \n",
    "    # Step 2 - Computes the loss\n",
    "    # No more manual loss!\n",
    "    # error = (yhat - y_train_tensor)\n",
    "    # loss = (error ** 2).mean()\n",
    "    loss = loss_fn(yhat, y_train_tensor)\n",
    "\n",
    "    # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    # Step 4 - Updates parameters using gradients and\n",
    "    # the learning rate\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tWFapoofyY4V"
   },
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8nzzmk58yY4V"
   },
   "outputs": [],
   "source": [
    "# Uncomment and Run this cell\n",
    "# This will give an error since the loss tensor is computing gradients and we first need to detach it. The data tensors (x_train and y_train) were not so detach wasn't necessary to use there. \n",
    "\n",
    "# loss.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AO8dMKTCyY4V"
   },
   "outputs": [],
   "source": [
    "loss.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TgSg87n2yY4V"
   },
   "outputs": [],
   "source": [
    "print(loss.item(), loss.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jo6AUELdyY4V"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3hFSvsWyY4W"
   },
   "source": [
    "### Cell 3.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "0MtoIGWcyY4W"
   },
   "outputs": [],
   "source": [
    "class ManualLinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # To make \"b\" and \"w\" real parameters of the model,\n",
    "        # we need to wrap them with nn.Parameter\n",
    "        self.b = nn.Parameter(torch.randn(1,\n",
    "                                          requires_grad=True, \n",
    "                                          dtype=torch.float))\n",
    "        self.w = nn.Parameter(torch.randn(1, \n",
    "                                          requires_grad=True,\n",
    "                                          dtype=torch.float))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Computes the outputs / predictions\n",
    "        return self.b + self.w * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dq9VNHyXyY4W"
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "KIf47_rvyY4W"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], requires_grad=True)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "# Creates a \"dummy\" instance of our ManualLinearRegression model\n",
    "dummy = ManualLinearRegression()\n",
    "list(dummy.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KrI6BzgtyY4W"
   },
   "source": [
    "## state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "YjLy5wvHyY4W"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('b', tensor([0.3367])), ('w', tensor([0.1288]))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "oVSW0Nh3yY4W"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': {},\n",
       " 'param_groups': [{'lr': 0.1,\n",
       "   'momentum': 0,\n",
       "   'dampening': 0,\n",
       "   'weight_decay': 0,\n",
       "   'nesterov': False,\n",
       "   'maximize': False,\n",
       "   'foreach': None,\n",
       "   'differentiable': False,\n",
       "   'fused': None,\n",
       "   'params': [0, 1]}]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ViZYPViyY4X"
   },
   "source": [
    "## device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_sg8h97LyY4X"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "# Creates a \"dummy\" instance of our ManualLinearRegression model\n",
    "# and sends it to the device\n",
    "dummy = ManualLinearRegression().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kgA5NBzGyY4X"
   },
   "source": [
    "## Forward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TlwwnypOyY4X"
   },
   "source": [
    "### Cell 3.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x-DilIZ3yY4X"
   },
   "outputs": [],
   "source": [
    "# Sets learning rate - this is \"eta\" ~ the \"n\"-like\n",
    "# Greek letter\n",
    "lr = 0.1\n",
    "\n",
    "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
    "torch.manual_seed(42)\n",
    "# Now we can create a model and send it at once to the device\n",
    "model = ManualLinearRegression().to(device)\n",
    "\n",
    "# Defines a SGD optimizer to update the parameters \n",
    "# (now retrieved directly from the model)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Defines a MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train() # What is this?!?\n",
    "\n",
    "    # Step 1 - Computes model's predicted output - forward pass\n",
    "    # No more manual prediction!\n",
    "    yhat = model(x_train_tensor)\n",
    "    \n",
    "    # Step 2 - Computes the loss\n",
    "    loss = loss_fn(yhat, y_train_tensor)\n",
    "\n",
    "    # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    # Step 4 - Updates parameters using gradients and\n",
    "    # the learning rate\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "# We can also inspect its parameters using its state_dict\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGfQfiFKyY4X"
   },
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L6nj7v6GyY4Y"
   },
   "outputs": [],
   "source": [
    "## Never forget to include model.train() in your training loop!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1pf2ZMU4yY4Y"
   },
   "source": [
    "## Nested Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6q5_MU2PyY4Y"
   },
   "outputs": [],
   "source": [
    "linear = nn.Linear(1, 1)\n",
    "linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dv7o9xEwyY4Y"
   },
   "outputs": [],
   "source": [
    "linear.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xvpdazlyY4Y"
   },
   "source": [
    "### Cell 3.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C2GKbDikyY4Y"
   },
   "outputs": [],
   "source": [
    "class MyLinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Instead of our custom parameters, we use a Linear model\n",
    "        # with single input and single output\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        # Now it only takes a call\n",
    "        self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TCrm8WTbyY4Z"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "dummy = MyLinearRegression().to(device)\n",
    "list(dummy.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MMy7W6ljyY4Z"
   },
   "outputs": [],
   "source": [
    "dummy.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zxgm6A8KyY4Z"
   },
   "source": [
    "## Sequential Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wH9bD7zkyY4Z"
   },
   "source": [
    "### Cell 3.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ZjcEqiOyY4Z"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "# Alternatively, you can use a Sequential model\n",
    "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
    "\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yryIChOyY4Z"
   },
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jIX_42EVyY4Z"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "# Building the model from the figure above\n",
    "model = nn.Sequential(nn.Linear(3, 5), nn.Linear(5, 1)).to(device)\n",
    "\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WgbHuMqmyY4a"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "# Building the model from the figure above\n",
    "model = nn.Sequential()\n",
    "model.add_module('layer1', nn.Linear(3, 5))\n",
    "model.add_module('layer2', nn.Linear(5, 1))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnNQZFGfyY4a"
   },
   "source": [
    "# Putting It All Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Vw3EYTayY4a"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85J79teDyY4a"
   },
   "source": [
    "### Data Preparation V0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tY7LftzzyY4a"
   },
   "outputs": [],
   "source": [
    "%%writefile data_preparation/v0.py\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Our data was in Numpy arrays, but we need to transform them\n",
    "# into PyTorch's Tensors and then we send them to the \n",
    "# chosen device\n",
    "x_train_tensor = torch.as_tensor(x_train).float().to(device)\n",
    "y_train_tensor = torch.as_tensor(y_train).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8lwtZPWyY4a"
   },
   "outputs": [],
   "source": [
    "%run -i data_preparation/v0.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZ-0vH4vyY4b"
   },
   "source": [
    "## Model Configurtion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQoWJEiGyY4b"
   },
   "source": [
    "### Model Configuration V0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RpBLRPx0yY4b"
   },
   "outputs": [],
   "source": [
    "%%writefile model_configuration/v0.py\n",
    "\n",
    "# This is redundant now, but it won't be when we introduce\n",
    "# Datasets...\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Sets learning rate - this is \"eta\" ~ the \"n\"-like Greek letter\n",
    "lr = 0.1\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# Now we can create a model and send it at once to the device\n",
    "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
    "\n",
    "# Defines a SGD optimizer to update the parameters \n",
    "# (now retrieved directly from the model)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Defines a MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5fupMU9dyY4b"
   },
   "outputs": [],
   "source": [
    "%run -i model_configuration/v0.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZRXXuOSyY4b"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13HtW807yY4b"
   },
   "source": [
    "### Model Training V0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "srCMSpdSyY4b"
   },
   "outputs": [],
   "source": [
    "%%writefile model_training/v0.py\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Sets model to TRAIN mode\n",
    "    model.train()\n",
    "\n",
    "    # Step 1 - Computes model's predicted output - forward pass\n",
    "    yhat = model(x_train_tensor)\n",
    "    \n",
    "    # Step 2 - Computes the loss\n",
    "    loss = loss_fn(yhat, y_train_tensor)\n",
    "\n",
    "    # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    # Step 4 - Updates parameters using gradients and \n",
    "    # the learning rate\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lnNGUx-xyY4c"
   },
   "outputs": [],
   "source": [
    "%run -i model_training/v0.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ufsqn3rnyY4c"
   },
   "outputs": [],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ehF-kib5yY4c"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "-MvpSz-ryY4A",
    "IrKLFkgAyY4B",
    "lFQgdk8AyY4B",
    "tnkhIBsayY4C",
    "u-zI7Dy5yY4C",
    "aC_mabQayY4E",
    "eNyqlUZsyY4E",
    "LcjE0Lx8yY4E",
    "zDZaGmpayY4F",
    "1UXnwOTEyY4F",
    "LZGSJEWdyY4G",
    "IkEEjMlmyY4G",
    "G4ygK45VyY4G",
    "10Cyal-6yY4H",
    "StXDn4jFyY4I",
    "fh-7KTtGyY4I",
    "he0RKFoMyY4J",
    "lS48mUwxyY4L",
    "V25EuOIdyY4L",
    "Z6uSAqV2yY4M",
    "oyuOimWjyY4N",
    "a2qN9fwiyY4O",
    "Fo5CBuZxyY4O",
    "Z8CVsB1FyY4O",
    "JeqPXn8AyY4P",
    "ctXPBqMkyY4Q",
    "Df8eVjFqyY4Q",
    "cCwV0t8RyY4Q",
    "n8WUoAflyY4R",
    "fMREmb0XyY4R",
    "4MyL9005yY4S",
    "Z29gacdZyY4S",
    "zmaf6B7OyY4T",
    "rRzsZ9D4yY4T",
    "8vPBkM1GyY4U",
    "Jo6AUELdyY4V",
    "V3hFSvsWyY4W",
    "Dq9VNHyXyY4W",
    "KrI6BzgtyY4W",
    "5ViZYPViyY4X",
    "kgA5NBzGyY4X",
    "TlwwnypOyY4X",
    "aGfQfiFKyY4X",
    "1pf2ZMU4yY4Y",
    "5xvpdazlyY4Y",
    "Zxgm6A8KyY4Z",
    "wH9bD7zkyY4Z",
    "5yryIChOyY4Z",
    "RnNQZFGfyY4a",
    "8Vw3EYTayY4a",
    "85J79teDyY4a",
    "YZ-0vH4vyY4b",
    "SQoWJEiGyY4b",
    "SZRXXuOSyY4b",
    "13HtW807yY4b"
   ],
   "name": "Chapter03.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
